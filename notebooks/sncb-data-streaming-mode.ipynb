{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7219356,"sourceType":"datasetVersion","datasetId":4178370},{"sourceId":155000202,"sourceType":"kernelVersion"},{"sourceId":155132920,"sourceType":"kernelVersion"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Import","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom geopy.distance import geodesic\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.metrics import mean_absolute_error\n\nfrom sklearn.neighbors import LocalOutlierFactor\n\nfrom sklearn.ensemble import IsolationForest\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, Dropout\nfrom keras.preprocessing.sequence import TimeseriesGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\n\nfrom joblib import dump\n\nfrom sklearn.decomposition import PCA\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\nimport plotly.graph_objs as go\n\nimport dask.dataframe as dd\n\nimport joblib\n\nimport gc\n\nimport pyarrow\n\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:24:06.088281Z","iopub.execute_input":"2023-12-17T12:24:06.089926Z","iopub.status.idle":"2023-12-17T12:24:06.103869Z","shell.execute_reply.started":"2023-12-17T12:24:06.089860Z","shell.execute_reply":"2023-12-17T12:24:06.102237Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"dataset_path = '/kaggle/input/sncb-data-augumentation/augumented_cleaned_ar41_for_ulb.csv'\n\n# # Define the columns that you want to load\n# columns_to_load = [\n#     'RS_E_InAirTemp_PC1', 'RS_E_InAirTemp_PC2', \n#     'RS_E_WatTemp_PC1', 'RS_E_WatTemp_PC2', \n#     'RS_T_OilTemp_PC1', 'RS_T_OilTemp_PC2',\n#     'RS_E_OilPress_PC2', 'RS_E_OilPress_PC2',\n#     'RS_E_RPM_PC1', 'RS_E_RPM_PC1',\n#     'Speed', 'lat', 'lon', 'mapped_veh_id', \n#     'hour', 'pm10', 'temp_celsius',\n#     'weather_main', 'date', 'timestamps_UTC'  # Include 'date' to convert to 'weekday' later\n# ]\n\n# Check if the file exists before trying to read it\nif os.path.exists(dataset_path):\n    # Read the specified columns of the CSV file into a DataFrame\n    data = pd.read_csv(dataset_path)\n\n    # Display the basic information and the first few rows of the dataframe\n    data_info = data.info()\n    data_head = data.head()\n\n    # If you want to print the information to the console\n    print(\"Dataframe Info:\")\n    print(data_info)\n    print(\"\\nFirst Few Rows of Data:\")\n    print(data_head)\nelse:\n    print(f\"The file {dataset_path} does not exist.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:05:34.589956Z","iopub.execute_input":"2023-12-17T12:05:34.591664Z","iopub.status.idle":"2023-12-17T12:08:55.627538Z","shell.execute_reply.started":"2023-12-17T12:05:34.591614Z","shell.execute_reply":"2023-12-17T12:08:55.626046Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17677337 entries, 0 to 17677336\nData columns (total 42 columns):\n #   Column              Dtype  \n---  ------              -----  \n 0   Unnamed: 0          int64  \n 1   timestamps_UTC      object \n 2   mapped_veh_id       float64\n 3   lat                 float64\n 4   lon                 float64\n 5   RS_E_InAirTemp_PC1  float64\n 6   RS_E_InAirTemp_PC2  float64\n 7   RS_E_OilPress_PC1   float64\n 8   RS_E_OilPress_PC2   float64\n 9   RS_E_RPM_PC1        float64\n 10  RS_E_RPM_PC2        float64\n 11  RS_E_WatTemp_PC1    float64\n 12  RS_E_WatTemp_PC2    float64\n 13  RS_T_OilTemp_PC1    float64\n 14  RS_T_OilTemp_PC2    float64\n 15  date                object \n 16  hour                float64\n 17  dayofweek           float64\n 18  weekday             object \n 19  Distance            float64\n 20  Speed               float64\n 21  date_hour           object \n 22  datetime_x          object \n 23  weather_main        object \n 24  temp                float64\n 25  feels_like          float64\n 26  pressure            float64\n 27  humidity            float64\n 28  wind                float64\n 29  clouds              float64\n 30  temp_celsius        float64\n 31  feels_like_celsius  float64\n 32  datetime_y          object \n 33  aqi                 float64\n 34  co                  float64\n 35  no                  float64\n 36  no2                 float64\n 37  o3                  float64\n 38  so2                 float64\n 39  pm2_5               float64\n 40  pm10                float64\n 41  nh3                 float64\ndtypes: float64(34), int64(1), object(7)\nmemory usage: 5.5+ GB\nDataframe Info:\nNone\n\nFirst Few Rows of Data:\n   Unnamed: 0       timestamps_UTC  mapped_veh_id    lat   lon  \\\n0           0  2023-01-23 07:25:08          102.0  51.02  3.77   \n1           1  2023-01-23 07:25:16          102.0  51.02  3.77   \n2           2  2023-01-23 07:25:37          102.0  51.02  3.77   \n3           3  2023-01-23 07:25:41          102.0  51.02  3.77   \n4           4  2023-01-23 07:26:10          102.0  51.02  3.77   \n\n   RS_E_InAirTemp_PC1  RS_E_InAirTemp_PC2  RS_E_OilPress_PC1  \\\n0                17.0                18.0              210.0   \n1                17.0                20.0              200.0   \n2                19.0                20.0              193.0   \n3                19.0                20.0              196.0   \n4                19.0                21.0              200.0   \n\n   RS_E_OilPress_PC2  RS_E_RPM_PC1  ...           datetime_y  aqi      co  \\\n0              210.0         858.0  ...  2023-01-23 07:00:00  2.0  353.81   \n1              200.0         801.0  ...  2023-01-23 07:00:00  2.0  353.81   \n2              207.0         803.0  ...  2023-01-23 07:00:00  2.0  353.81   \n3              203.0         801.0  ...  2023-01-23 07:00:00  2.0  353.81   \n4              203.0         795.0  ...  2023-01-23 07:00:00  2.0  353.81   \n\n     no    no2    o3   so2  pm2_5   pm10   nh3  \n0  8.94  40.44  0.21  7.51  11.17  12.77  6.52  \n1  8.94  40.44  0.21  7.51  11.17  12.77  6.52  \n2  8.94  40.44  0.21  7.51  11.17  12.77  6.52  \n3  8.94  40.44  0.21  7.51  11.17  12.77  6.52  \n4  8.94  40.44  0.21  7.51  11.17  12.77  6.52  \n\n[5 rows x 42 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"del data_info\ndel data_head\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:08:55.630034Z","iopub.execute_input":"2023-12-17T12:08:55.630511Z","iopub.status.idle":"2023-12-17T12:08:55.938739Z","shell.execute_reply.started":"2023-12-17T12:08:55.630462Z","shell.execute_reply":"2023-12-17T12:08:55.937253Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"53"},"metadata":{}}]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" Iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if np.issubdtype(col_type, np.number):  # Check if column type is numeric\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type).startswith('int'):\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        # You can add more conditions here for other data types if necessary\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:08:55.942583Z","iopub.execute_input":"2023-12-17T12:08:55.943091Z","iopub.status.idle":"2023-12-17T12:08:55.960790Z","shell.execute_reply.started":"2023-12-17T12:08:55.943046Z","shell.execute_reply":"2023-12-17T12:08:55.959555Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Apply the memory reduction\ndata = reduce_mem_usage(data)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:08:55.962148Z","iopub.execute_input":"2023-12-17T12:08:55.962540Z","iopub.status.idle":"2023-12-17T12:09:04.549603Z","shell.execute_reply.started":"2023-12-17T12:08:55.962509Z","shell.execute_reply":"2023-12-17T12:09:04.548095Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Memory usage of dataframe is 5664.43 MB\nMemory usage after optimization is: 2157.88 MB\nDecreased by 61.9%\n","output_type":"stream"}]},{"cell_type":"code","source":"# data = data.drop(['Unnamed: 0', 'dayofweek', 'date_hour'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:09:04.552102Z","iopub.execute_input":"2023-12-17T12:09:04.552626Z","iopub.status.idle":"2023-12-17T12:09:04.558833Z","shell.execute_reply.started":"2023-12-17T12:09:04.552579Z","shell.execute_reply":"2023-12-17T12:09:04.557433Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# data.head(500000).to_csv('mini_augumented_cleaned_ar41_for_ulb.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:09:04.560562Z","iopub.execute_input":"2023-12-17T12:09:04.560980Z","iopub.status.idle":"2023-12-17T12:09:04.572066Z","shell.execute_reply.started":"2023-12-17T12:09:04.560935Z","shell.execute_reply":"2023-12-17T12:09:04.570805Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Status Label (running | stopped)","metadata":{}},{"cell_type":"code","source":"stopped_threshold = 10  # Speed less than 10 for being stopped\nminimum_stopped_minutes = 30  # Minimum duration for stopped status","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:09:04.573265Z","iopub.execute_input":"2023-12-17T12:09:04.573628Z","iopub.status.idle":"2023-12-17T12:09:04.582575Z","shell.execute_reply.started":"2023-12-17T12:09:04.573596Z","shell.execute_reply":"2023-12-17T12:09:04.581331Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Convert timestamps to datetime and sort\ndata['timestamps_UTC'] = pd.to_datetime(data['timestamps_UTC'])\ndata = data.sort_values('timestamps_UTC')\n\n# Calculate time differences in minutes\ndata['time_diff'] = data['timestamps_UTC'].diff().dt.total_seconds() / 60.0\n\n# Identify rows where the vehicle is stopped\ndata['is_stopped'] = data['Speed'] < stopped_threshold\n\n# Forward-fill the 'is_stopped' status only within the groups where the vehicle is stopped\ndata['stopped_group'] = data['is_stopped'].ne(data['is_stopped'].shift()).cumsum()\ndata.loc[data['is_stopped'], 'stopped_group'] = data.loc[data['is_stopped'], 'stopped_group']\n\n# Calculate the cumulative stopped time in minutes only for stopped groups\ndata['cumulative_stopped_time'] = data.groupby('stopped_group')['time_diff'].cumsum().fillna(0)\n\n# Determine the stopped groups that exceed the minimum stopped duration\nstopped_groups = data[data['cumulative_stopped_time'] > minimum_stopped_minutes]['stopped_group'].unique()\n\n# Mark the status based on the identified stopped groups\ndata['status'] = 'running'\ndata.loc[data['stopped_group'].isin(stopped_groups), 'status'] = 'stopped'","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:09:04.584627Z","iopub.execute_input":"2023-12-17T12:09:04.585014Z","iopub.status.idle":"2023-12-17T12:09:30.599590Z","shell.execute_reply.started":"2023-12-17T12:09:04.584955Z","shell.execute_reply":"2023-12-17T12:09:30.598050Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data = data.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:09:30.603408Z","iopub.execute_input":"2023-12-17T12:09:30.603800Z","iopub.status.idle":"2023-12-17T12:09:52.738600Z","shell.execute_reply.started":"2023-12-17T12:09:30.603768Z","shell.execute_reply":"2023-12-17T12:09:52.737257Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Load the Models","metadata":{}},{"cell_type":"code","source":"# Load Isolation Forest model\niso_forest_model_path = '/kaggle/input/sncb-data-label-isolation-forest/isolation_forest_model.joblib'\niso_forest_model = joblib.load(iso_forest_model_path)\n\n# Load LSTM Autoencoder model\nlstm_autoencoder_model_path = '/kaggle/input/lstm-anomely-detection/lstm_autoencoder_model.h5'\nlstm_autoencoder_model = load_model(lstm_autoencoder_model_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:09:52.742570Z","iopub.execute_input":"2023-12-17T12:09:52.743058Z","iopub.status.idle":"2023-12-17T12:09:53.918453Z","shell.execute_reply.started":"2023-12-17T12:09:52.743022Z","shell.execute_reply":"2023-12-17T12:09:53.917277Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing Function","metadata":{}},{"cell_type":"code","source":"# Function to preprocess data\ndef preprocess_data(data, scaler=None, encoder=None):\n    # Define numeric and categorical features\n    numeric_features = [\n        'RS_E_InAirTemp_PC1', 'RS_E_InAirTemp_PC2', \n        'RS_E_WatTemp_PC1', 'RS_E_WatTemp_PC2', \n        'RS_T_OilTemp_PC1', 'RS_T_OilTemp_PC2', \n        'Speed', 'lat', 'lon', 'mapped_veh_id', \n        'hour', 'pm10', 'temp_celsius', 'weekday'\n    ]\n    categorical_features = ['weather_main', 'status']\n\n    # Convert 'weekday' to a numerical format\n    data['weekday'] = pd.to_datetime(data['date']).dt.dayofweek\n\n    # Standardize numeric features\n    if scaler is None:\n        scaler = StandardScaler()\n        X_numeric_scaled = scaler.fit_transform(data[numeric_features])\n    else:\n        X_numeric_scaled = scaler.transform(data[numeric_features])\n\n    # Encode categorical features\n    if encoder is None:\n        encoder = OneHotEncoder(sparse=False)\n        X_categorical_encoded = encoder.fit_transform(data[categorical_features])\n    else:\n        X_categorical_encoded = encoder.transform(data[categorical_features])\n\n    # Combine numeric and categorical data\n    X_combined = np.hstack((X_numeric_scaled, X_categorical_encoded))\n    \n    return X_combined, scaler, encoder","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:09:53.919999Z","iopub.execute_input":"2023-12-17T12:09:53.920651Z","iopub.status.idle":"2023-12-17T12:09:53.936332Z","shell.execute_reply.started":"2023-12-17T12:09:53.920608Z","shell.execute_reply":"2023-12-17T12:09:53.934994Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Preprocess the sample data for demonstration\nX_combined, scaler, encoder = preprocess_data(data)\nX_combined.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:09:53.938249Z","iopub.execute_input":"2023-12-17T12:09:53.938881Z","iopub.status.idle":"2023-12-17T12:10:26.187167Z","shell.execute_reply.started":"2023-12-17T12:09:53.938838Z","shell.execute_reply":"2023-12-17T12:10:26.185462Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(17480996, 25)"},"metadata":{}}]},{"cell_type":"code","source":"# pd.DataFrame(X_combined).head(50000).to_csv('X_combined_streaming.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:10:26.189202Z","iopub.execute_input":"2023-12-17T12:10:26.189707Z","iopub.status.idle":"2023-12-17T12:10:26.195659Z","shell.execute_reply.started":"2023-12-17T12:10:26.189662Z","shell.execute_reply":"2023-12-17T12:10:26.194490Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Simulating Data Streaming","metadata":{}},{"cell_type":"code","source":"# Function to simulate data streaming\ndef stream_data(data, batch_size=100):\n    for i in range(0, len(data), batch_size):\n        # Yield a batch of data\n        yield data[i:i + batch_size]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:10:26.197274Z","iopub.execute_input":"2023-12-17T12:10:26.198357Z","iopub.status.idle":"2023-12-17T12:10:26.207907Z","shell.execute_reply.started":"2023-12-17T12:10:26.198310Z","shell.execute_reply":"2023-12-17T12:10:26.206485Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Anomaly Detection in Streaming Mode","metadata":{}},{"cell_type":"code","source":"# # Function to detect anomalies\n# def detect_anomalies(batch, iso_forest_model, lstm_autoencoder_model):\n#     # Isolation Forest prediction\n#     iso_forest_pred = iso_forest_model.predict(batch)\n\n#     # LSTM Autoencoder prediction\n#     # Reshape data for LSTM (assuming the model expects 3D input)\n#     batch_reshaped = np.reshape(batch, (batch.shape[0], 1, batch.shape[1]))\n#     reconstructed = lstm_autoencoder_model.predict(batch_reshaped)\n#     mse = np.mean(np.power(batch_reshaped - reconstructed, 2), axis=1)\n#     # A threshold for anomaly detection in LSTM Autoencoder (needs to be defined)\n#     lstm_threshold = 0.5  # This is an example value\n#     lstm_pred = mse > lstm_threshold\n\n#     return iso_forest_pred, lstm_pred","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:10:26.209509Z","iopub.execute_input":"2023-12-17T12:10:26.210105Z","iopub.status.idle":"2023-12-17T12:10:26.222240Z","shell.execute_reply.started":"2023-12-17T12:10:26.210060Z","shell.execute_reply":"2023-12-17T12:10:26.220878Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def detect_anomalies(batch, iso_forest_model, lstm_autoencoder_model, iso_threshold=-0.1, lstm_threshold=2.5):\n    # Reshape data for Isolation Forest (flatten the 3D batch to 2D)\n    batch_flattened = batch.reshape(batch.shape[0] * batch.shape[1], -1)\n    scores = iso_forest_model.decision_function(batch_flattened)\n    iso_forest_anomalies = np.where(scores < iso_threshold)[0]  # Custom threshold\n\n    # LSTM Autoencoder prediction (final step)\n    reconstructed = lstm_autoencoder_model.predict(batch)\n    actual_final_step = batch[:, -1, :]\n    mse = np.mean(np.power(actual_final_step - reconstructed, 2), axis=1)\n    lstm_pred = mse > lstm_threshold\n    lstm_anomalies = np.where(lstm_pred)[0]\n\n    return iso_forest_anomalies, lstm_anomalies","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:32:29.596829Z","iopub.execute_input":"2023-12-17T12:32:29.597234Z","iopub.status.idle":"2023-12-17T12:32:29.605744Z","shell.execute_reply.started":"2023-12-17T12:32:29.597201Z","shell.execute_reply":"2023-12-17T12:32:29.604480Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"# Load Sample Data for Simulation","metadata":{}},{"cell_type":"code","source":"def batch_generator(data, sequence_length, batch_size, n_features):\n    num_batches = int(np.ceil((data.shape[0] - sequence_length) / batch_size))\n    while True:  # Loop forever so the generator never terminates\n        for batch_index in range(num_batches):\n            start_index = batch_index * batch_size\n            end_index = start_index + sequence_length + batch_size - 1  # Adjusted end_index calculation\n            \n            # Ensure we do not go past the end of the data\n            end_index = min(end_index, data.shape[0] - 1)\n            \n            batch_data = data[start_index:end_index]\n\n            # Adjust batch size if we're at the end and have less than a full batch left\n            current_batch_size = min(batch_size, data.shape[0] - start_index - sequence_length)\n            X_batch = np.zeros((current_batch_size, sequence_length, n_features))\n            y_batch = np.zeros((current_batch_size, n_features))\n\n            for i in range(current_batch_size):\n                end_seq_index = i + sequence_length\n                # Make sure we don't go beyond the end of batch_data when creating the sequence\n                if end_seq_index < batch_data.shape[0]:\n                    X_batch[i] = batch_data[i:end_seq_index]\n                    y_batch[i] = batch_data[end_seq_index]\n                else:\n                    # If not enough data for a full sequence, break the loop early\n                    break\n\n            yield X_batch, y_batch","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:10:26.223839Z","iopub.execute_input":"2023-12-17T12:10:26.224369Z","iopub.status.idle":"2023-12-17T12:10:26.238372Z","shell.execute_reply.started":"2023-12-17T12:10:26.224335Z","shell.execute_reply":"2023-12-17T12:10:26.237200Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"n_features = X_combined.shape[1]  # Number of features\n\n# Define sequence length (the window size) and batch size\nsequence_length = 10  # This is a hyperparameter you can tune\nbatch_size = 1024 \n\n# Initialize streaming data generator\nstreaming_data = batch_generator(X_combined, sequence_length, batch_size, n_features)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:16:23.748798Z","iopub.execute_input":"2023-12-17T12:16:23.749363Z","iopub.status.idle":"2023-12-17T12:16:23.755457Z","shell.execute_reply.started":"2023-12-17T12:16:23.749326Z","shell.execute_reply":"2023-12-17T12:16:23.754558Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Example of processing the data stream\nfor X_batch, _ in streaming_data:  # Unpack the tuple to get only the input data\n    iso_forest_pred, lstm_pred = detect_anomalies(X_batch, iso_forest_model, lstm_autoencoder_model)\n    # Process the results as needed (logging, alerts, etc.)\n    print(\"Batch processed. Isolation Forest Anomalies:\", np.sum(iso_forest_pred == -1),\n          \"LSTM Autoencoder Anomalies:\", np.sum(lstm_pred))\n    # Break after one batch for demonstration purposes\n    break","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:25:44.602137Z","iopub.execute_input":"2023-12-17T12:25:44.602536Z","iopub.status.idle":"2023-12-17T12:25:45.378086Z","shell.execute_reply.started":"2023-12-17T12:25:44.602508Z","shell.execute_reply":"2023-12-17T12:25:45.377230Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 0s 5ms/step\nBatch processed. Isolation Forest Anomalies: 0 LSTM Autoencoder Anomalies: 138101\n","output_type":"stream"}]},{"cell_type":"code","source":"# Process the data stream\nfor i, (X_batch, _) in enumerate(streaming_data):\n    iso_forest_anomalies, lstm_anomalies = detect_anomalies(X_batch, iso_forest_model, lstm_autoencoder_model)\n    print(f\"Batch {i} processed. Isolation Forest Anomalies:\", len(iso_forest_anomalies),\n          \"LSTM Autoencoder Anomalies:\", len(lstm_anomalies))\n\n    # Output specific information for anomalies\n    if len(iso_forest_anomalies) > 0 or len(lstm_anomalies) > 0:\n        # Assuming 'data' is the original DataFrame\n        # Select the columns you want to display\n        selected_columns = ['timestamps_UTC', 'lat', 'lon', 'RS_E_WatTemp_PC1', 'RS_T_OilTemp_PC1', 'RS_E_InAirTemp_PC1', 'Speed', 'status']\n        anomaly_indices = np.unique(np.concatenate((iso_forest_anomalies, lstm_anomalies)))\n        print(\"Anomaly details:\")\n        print(data.loc[anomaly_indices, selected_columns])\n\n    # Break after a few batches for demonstration purposes\n    if i >= 5:\n        break\n\n    # Delay for 2 seconds before the next batch\n    time.sleep(2)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T12:36:26.166769Z","iopub.execute_input":"2023-12-17T12:36:26.167299Z","iopub.status.idle":"2023-12-17T12:36:46.500672Z","shell.execute_reply.started":"2023-12-17T12:36:26.167261Z","shell.execute_reply":"2023-12-17T12:36:46.498907Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 0s 5ms/step\nBatch 0 processed. Isolation Forest Anomalies: 0 LSTM Autoencoder Anomalies: 17\nAnomaly details:\n         timestamps_UTC       lat       lon  RS_E_WatTemp_PC1  \\\n26  2023-01-23 14:17:11  51.03125  3.769531              43.0   \n123 2023-01-23 15:03:11  51.03125  3.769531              61.0   \n219 2023-01-23 15:54:11  51.03125  3.710938              68.0   \n222 2023-01-23 15:57:14  51.03125  3.699219              68.0   \n282 2023-01-23 16:33:09  51.03125  3.720703              72.0   \n291 2023-01-23 16:37:15  51.03125  3.759766              75.0   \n322 2023-01-23 16:53:06  51.12500  3.689453              81.0   \n331 2023-01-23 16:57:14  51.12500  3.640625              82.0   \n415 2023-01-23 17:37:11  51.06250  3.740234              80.0   \n425 2023-01-23 17:42:15  51.03125  3.730469              78.0   \n505 2023-01-23 18:22:15  50.87500  3.630859              81.0   \n508 2023-01-23 18:24:15  50.87500  3.619141              78.0   \n602 2023-01-23 19:16:11  50.75000  3.619141              81.0   \n698 2023-01-23 20:07:10  51.03125  3.710938              78.0   \n702 2023-01-23 20:09:10  51.03125  3.710938              79.0   \n804 2023-01-23 21:00:10  51.18750  3.580078              79.0   \n813 2023-01-23 21:04:16  51.18750  3.580078              78.0   \n\n     RS_T_OilTemp_PC1  RS_E_InAirTemp_PC1      Speed   status  \n26               27.0                 5.0   2.785156  stopped  \n123              56.0                 6.0   2.992188  stopped  \n219              62.0                13.0  28.218750  running  \n222              65.0                12.0  25.015625  running  \n282              67.0                 9.0  28.656250  running  \n291              74.0                15.0  27.609375  running  \n322              80.0                38.0  72.937500  running  \n331              81.0                36.0  88.625000  running  \n415              81.0                28.0  30.859375  running  \n425              77.0                32.0  46.062500  running  \n505              76.0                32.0  82.000000  running  \n508              77.0                28.0   2.960938  running  \n602              75.5                14.5  53.281250  running  \n698              76.0                15.0   2.738281  running  \n702              75.0                13.0   2.914062  running  \n804              74.0                13.0   3.101562  running  \n813              73.0                11.0   2.865234  running  \n32/32 [==============================] - 0s 5ms/step\nBatch 1 processed. Isolation Forest Anomalies: 0 LSTM Autoencoder Anomalies: 1\nAnomaly details:\n         timestamps_UTC     lat       lon  RS_E_WatTemp_PC1  RS_T_OilTemp_PC1  \\\n965 2023-01-23 22:25:12  50.875  3.619141              80.0              79.0   \n\n     RS_E_InAirTemp_PC1     Speed   status  \n965                28.0  0.258789  running  \n32/32 [==============================] - 0s 5ms/step\nBatch 2 processed. Isolation Forest Anomalies: 0 LSTM Autoencoder Anomalies: 4\nAnomaly details:\n         timestamps_UTC       lat       lon  RS_E_WatTemp_PC1  \\\n29  2023-01-23 14:18:17  51.03125  3.769531              45.0   \n123 2023-01-23 15:03:11  51.03125  3.769531              61.0   \n213 2023-01-23 15:51:07  51.03125  3.730469              68.0   \n290 2023-01-23 16:37:13  51.03125  3.759766              74.0   \n\n     RS_T_OilTemp_PC1  RS_E_InAirTemp_PC1      Speed   status  \n29               29.0                 6.0   2.677734  stopped  \n123              56.0                 6.0   2.992188  stopped  \n213              62.0                11.0  22.984375  running  \n290              71.0                15.0  28.546875  running  \n32/32 [==============================] - 0s 5ms/step\nBatch 3 processed. Isolation Forest Anomalies: 0 LSTM Autoencoder Anomalies: 0\n32/32 [==============================] - 0s 4ms/step\nBatch 4 processed. Isolation Forest Anomalies: 0 LSTM Autoencoder Anomalies: 0\n32/32 [==============================] - 0s 5ms/step\nBatch 5 processed. Isolation Forest Anomalies: 0 LSTM Autoencoder Anomalies: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save to CSV","metadata":{}},{"cell_type":"code","source":"data.to_csv('labeled_augumented_cleaned_ar41_for_ulb.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T02:04:32.042712Z","iopub.status.idle":"2023-12-17T02:04:32.043063Z","shell.execute_reply.started":"2023-12-17T02:04:32.042894Z","shell.execute_reply":"2023-12-17T02:04:32.04291Z"},"trusted":true},"execution_count":null,"outputs":[]}]}